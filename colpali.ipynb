{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMESKJNjAZj4Y/mm+TL0CFy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinishgeorge/google-colab/blob/main/colpali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPJ9MZcXoIm4",
        "outputId": "2cdbfafd-c8af-4890-a274-960afba2d046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "CUDA device count: 1\n",
            "Current CUDA device: 0\n",
            "CUDA device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
        "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install colpali_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8SfDUJ4x6v0",
        "outputId": "55d37e7b-b7c4-425d-a821-d3fdfc0ec4fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting colpali_engine\n",
            "  Downloading colpali_engine-0.3.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting gputil (from colpali_engine)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from colpali_engine) (1.26.4)\n",
            "Requirement already satisfied: peft<0.15.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from colpali_engine) (0.14.0)\n",
            "Requirement already satisfied: pillow>=10.0.0 in /usr/local/lib/python3.11/dist-packages (from colpali_engine) (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from colpali_engine) (2.32.3)\n",
            "Requirement already satisfied: torch>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from colpali_engine) (2.5.1+cu124)\n",
            "Collecting transformers<4.48.0,>=4.47.0 (from colpali_engine)\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (1.3.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft<0.15.0,>=0.14.0->colpali_engine) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.2.0->colpali_engine)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.2.0->colpali_engine) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.2.0->colpali_engine) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<4.48.0,>=4.47.0->colpali_engine) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.48.0,>=4.47.0->colpali_engine) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->colpali_engine) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->colpali_engine) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->colpali_engine) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->colpali_engine) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.2.0->colpali_engine) (3.0.2)\n",
            "Downloading colpali_engine-0.3.8-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=9d627f7f7a8c6f8b567066f43553404fb4cbcb14ab671f62ec2c629ffd79a212\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/4d/8f/55fb4f7b9b591891e8d3f72977c4ec6c7763b39c19f0861595\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, colpali_engine\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed colpali_engine-0.3.8 gputil-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.47.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install requests Pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpTL0vHiyvrj",
        "outputId": "69841995-a1da-4a86-cebf-b65806c3f189"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# Array of image URLs\n",
        "urls = [\n",
        "    \"https://vinishgeorgesandboxdiag.blob.core.windows.net/images/copali_test1.png\",\n",
        "    \"https://vinishgeorgesandboxdiag.blob.core.windows.net/images/copali_test2.png\"\n",
        "]\n",
        "\n",
        "# List to store all the fetched images\n",
        "images = []\n",
        "\n",
        "# Process each URL in the array\n",
        "for i, url in enumerate(urls):\n",
        "    try:\n",
        "        # Fetch the image from the URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Check if the request was successful\n",
        "        if response.status_code == 200:\n",
        "            # Convert the response content to an image\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "\n",
        "            # Resize it to 128x128 if needed\n",
        "            img = img.resize((128, 128))\n",
        "\n",
        "            # Add to our images list\n",
        "            images.append(img)\n",
        "\n",
        "            # Save the image with a unique name\n",
        "            img.save(f\"downloaded_image_{i}.jpg\")\n",
        "\n",
        "            print(f\"Successfully downloaded image from {url}\")\n",
        "        else:\n",
        "            print(f\"Failed to fetch image from {url}: HTTP {response.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {str(e)}\")\n",
        "\n",
        "# Now 'images' contains all the successfully downloaded PIL Image objects\n",
        "print(f\"Total images downloaded: {len(images)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJmWOdm61oi7",
        "outputId": "0460858f-685d-4186-9142-6171fbc7cba9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing https://vinishgeorgesandboxdiag.blob.core.windows.net/images/copali_test1.png: cannot write mode RGBA as JPEG\n",
            "Error processing https://vinishgeorgesandboxdiag.blob.core.windows.net/images/copali_test2.png: cannot write mode RGBA as JPEG\n",
            "Total images downloaded: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers.utils.import_utils import is_flash_attn_2_available\n",
        "\n",
        "from colpali_engine.models import ColQwen2, ColQwen2Processor\n",
        "\n",
        "model_name = \"vidore/colqwen2-v1.0\"\n",
        "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "model = ColQwen2.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"cpu\",\n",
        "    attn_implementation=\"flash_attention_2\" if is_flash_attn_2_available() else None,\n",
        ").eval()\n",
        "\n",
        "processor = ColQwen2Processor.from_pretrained(model_name)\n",
        "\n",
        "# Your inputs\n",
        "\n",
        "queries = [\n",
        "    \"how can i get all the assessment results of the user?\",\n",
        "    \"what are the features associated with assessments?\",\n",
        "]\n",
        "\n",
        "# Process the inputs\n",
        "batch_images = processor.process_images(images).to(model.device)\n",
        "batch_queries = processor.process_queries(queries).to(model.device)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    image_embeddings = model(**batch_images)\n",
        "    query_embeddings = model(**batch_queries)\n",
        "\n",
        "scores = processor.score_multi_vector(query_embeddings, image_embeddings)"
      ],
      "metadata": {
        "id": "E_naaF38oRYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this code after computing the scores\n",
        "\n",
        "# Convert scores to a more readable format\n",
        "def interpret_scores(scores, queries, image_urls):\n",
        "    # Convert to numpy for easier handling\n",
        "    scores_np = scores.cpu().numpy()\n",
        "\n",
        "    # Print human-readable results\n",
        "    print(\"\\n===== QUERY-IMAGE MATCH RESULTS =====\\n\")\n",
        "\n",
        "    for i, query in enumerate(queries):\n",
        "        print(f\"Query {i+1}: \\\"{query}\\\"\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        # Get scores for this query against all images\n",
        "        query_scores = scores_np[i]\n",
        "\n",
        "        # Sort images by relevance for this query\n",
        "        sorted_indices = query_scores.argsort()[::-1]  # Descending order\n",
        "\n",
        "        for rank, idx in enumerate(sorted_indices):\n",
        "            score = query_scores[idx]\n",
        "            url = image_urls[idx]\n",
        "            filename = url.split('/')[-1]\n",
        "\n",
        "            # Convert score to percentage for better readability\n",
        "            score_percent = score * 100 if score <= 1.0 else score\n",
        "\n",
        "            print(f\"Rank {rank+1}: Image '{filename}'\")\n",
        "            print(f\"   Score: {score:.4f} ({score_percent:.2f}%)\")\n",
        "            print(f\"   URL: {url}\")\n",
        "            print()\n",
        "\n",
        "        # Best match for this query\n",
        "        best_idx = scores_np[i].argmax()\n",
        "        best_score = scores_np[i][best_idx]\n",
        "        best_image = image_urls[best_idx].split('/')[-1]\n",
        "\n",
        "        print(f\"Best match for query: '{best_image}' with score {best_score:.4f}\\n\")\n",
        "        print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "    # Print overall top matches\n",
        "    print(\"\\n===== OVERALL TOP MATCHES =====\\n\")\n",
        "\n",
        "    # Flatten scores to find top matches overall\n",
        "    flat_scores = scores_np.flatten()\n",
        "    flat_indices = flat_scores.argsort()[::-1][:5]  # Top 5 matches\n",
        "\n",
        "    for rank, flat_idx in enumerate(flat_indices):\n",
        "        # Convert flat index to query and image indices\n",
        "        query_idx = flat_idx // len(image_urls)\n",
        "        image_idx = flat_idx % len(image_urls)\n",
        "\n",
        "        score = flat_scores[flat_idx]\n",
        "        query = queries[query_idx]\n",
        "        image = image_urls[image_idx].split('/')[-1]\n",
        "\n",
        "        print(f\"Overall Rank {rank+1}:\")\n",
        "        print(f\"   Query: \\\"{query}\\\"\")\n",
        "        print(f\"   Image: {image}\")\n",
        "        print(f\"   Score: {score:.4f}\")\n",
        "        print()\n",
        "\n",
        "# Call the function\n",
        "interpret_scores(scores, queries, urls)\n",
        "\n",
        "# You can also visualize the results with a heatmap\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_similarity_heatmap(scores, queries, image_urls):\n",
        "    # Convert to numpy\n",
        "    scores_np = scores.cpu().numpy()\n",
        "\n",
        "    # Create labels for the plot\n",
        "    image_labels = [url.split('/')[-1] for url in image_urls]\n",
        "    query_labels = [f\"Q{i+1}: {q[:20]}...\" if len(q) > 20 else f\"Q{i+1}: {q}\" for i, q in enumerate(queries)]\n",
        "\n",
        "    # Create the figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    heatmap = plt.imshow(scores_np, cmap='viridis')\n",
        "    plt.colorbar(heatmap, label='Similarity Score')\n",
        "\n",
        "    # Add labels\n",
        "    plt.xticks(np.arange(len(image_labels)), image_labels, rotation=45, ha='right')\n",
        "    plt.yticks(np.arange(len(query_labels)), query_labels)\n",
        "\n",
        "    # Add values on the heatmap\n",
        "    for i in range(len(query_labels)):\n",
        "        for j in range(len(image_labels)):\n",
        "            plt.text(j, i, f\"{scores_np[i, j]:.2f}\",\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if scores_np[i, j] > 0.5 else \"black\")\n",
        "\n",
        "    plt.title('Query-Image Similarity Scores')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('similarity_heatmap.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"Heatmap saved as 'similarity_heatmap.png'\")\n",
        "\n",
        "# Generate the heatmap\n",
        "plot_similarity_heatmap(scores, queries, urls)"
      ],
      "metadata": {
        "id": "-75eXAx62rr1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}